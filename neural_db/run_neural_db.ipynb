{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ThirdAI's NeuralDB\n",
    "\n",
    "NeuralDB, as the name suggests, is a combination of a neural network and a database. It provides a high-level API for users to insert different types of files into it and search through the file contents with natural language queries. The neural network part of it enables semantic search while the database part of it stores the paragraphs of the files that are inserted into it.\n",
    "\n",
    "First, let's install the dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: thirdai in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.7.16)\n",
      "Requirement already satisfied: numpy in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thirdai) (1.24.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thirdai) (4.6.3)\n",
      "Requirement already satisfied: requests in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thirdai) (2.31.0)\n",
      "Requirement already satisfied: pandas>=1.2.0 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thirdai) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.2.0->thirdai) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.2.0->thirdai) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.2.0->thirdai) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->thirdai) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->thirdai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->thirdai) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->thirdai) (2023.5.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->thirdai) (1.16.0)\n",
      "Requirement already satisfied: thirdai[neural_db] in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.7.16)\n",
      "Requirement already satisfied: numpy in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thirdai[neural_db]) (1.24.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thirdai[neural_db]) (4.6.3)\n",
      "Requirement already satisfied: requests in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thirdai[neural_db]) (2.31.0)\n",
      "Requirement already satisfied: pandas>=1.2.0 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thirdai[neural_db]) (2.0.2)\n",
      "Requirement already satisfied: PyTrie in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thirdai[neural_db]) (0.4.0)\n",
      "Requirement already satisfied: PyMuPDF in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thirdai[neural_db]) (1.22.5)\n",
      "Requirement already satisfied: langchain in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thirdai[neural_db]) (0.0.198)\n",
      "Requirement already satisfied: bs4 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thirdai[neural_db]) (0.0.1)\n",
      "Requirement already satisfied: trafilatura in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thirdai[neural_db]) (1.6.1)\n",
      "Requirement already satisfied: python-docx in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thirdai[neural_db]) (0.8.11)\n",
      "Requirement already satisfied: url-normalize in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thirdai[neural_db]) (1.4.3)\n",
      "Requirement already satisfied: nltk in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thirdai[neural_db]) (3.8.1)\n",
      "Requirement already satisfied: unidecode in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thirdai[neural_db]) (1.3.6)\n",
      "Requirement already satisfied: pydantic in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thirdai[neural_db]) (1.10.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.2.0->thirdai[neural_db]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.2.0->thirdai[neural_db]) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.2.0->thirdai[neural_db]) (2023.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bs4->thirdai[neural_db]) (4.12.2)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain->thirdai[neural_db]) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain->thirdai[neural_db]) (2.0.16)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain->thirdai[neural_db]) (3.8.4)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain->thirdai[neural_db]) (0.5.8)\n",
      "Requirement already satisfied: langchainplus-sdk>=0.0.7 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain->thirdai[neural_db]) (0.0.8)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain->thirdai[neural_db]) (2.8.4)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain->thirdai[neural_db]) (1.2.4)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain->thirdai[neural_db]) (8.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->thirdai[neural_db]) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->thirdai[neural_db]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->thirdai[neural_db]) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->thirdai[neural_db]) (2023.5.7)\n",
      "Requirement already satisfied: click in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->thirdai[neural_db]) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->thirdai[neural_db]) (1.3.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->thirdai[neural_db]) (2023.6.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->thirdai[neural_db]) (4.65.0)\n",
      "Requirement already satisfied: lxml>=2.3.2 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-docx->thirdai[neural_db]) (4.9.3)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from PyTrie->thirdai[neural_db]) (2.4.0)\n",
      "Requirement already satisfied: courlan>=0.9.3 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trafilatura->thirdai[neural_db]) (0.9.3)\n",
      "Requirement already satisfied: htmldate>=1.4.3 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trafilatura->thirdai[neural_db]) (1.4.3)\n",
      "Requirement already satisfied: justext>=3.0.0 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trafilatura->thirdai[neural_db]) (3.0.0)\n",
      "Requirement already satisfied: six in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from url-normalize->thirdai[neural_db]) (1.16.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->thirdai[neural_db]) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->thirdai[neural_db]) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->thirdai[neural_db]) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->thirdai[neural_db]) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->thirdai[neural_db]) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->thirdai[neural_db]) (1.3.1)\n",
      "Requirement already satisfied: langcodes>=3.3.0 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from courlan>=0.9.3->trafilatura->thirdai[neural_db]) (3.3.0)\n",
      "Requirement already satisfied: tld>=0.13 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from courlan>=0.9.3->trafilatura->thirdai[neural_db]) (0.13)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain->thirdai[neural_db]) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain->thirdai[neural_db]) (1.5.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain->thirdai[neural_db]) (0.9.0)\n",
      "Requirement already satisfied: dateparser>=1.1.2 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from htmldate>=1.4.3->trafilatura->thirdai[neural_db]) (1.1.8)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain->thirdai[neural_db]) (2.0.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from beautifulsoup4->bs4->thirdai[neural_db]) (2.4.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click->nltk->thirdai[neural_db]) (0.4.6)\n",
      "Requirement already satisfied: tzlocal in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dateparser>=1.1.2->htmldate>=1.4.3->trafilatura->thirdai[neural_db]) (4.3)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain->thirdai[neural_db]) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain->thirdai[neural_db]) (1.0.0)\n",
      "Requirement already satisfied: pytz-deprecation-shim in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tzlocal->dateparser>=1.1.2->htmldate>=1.4.3->trafilatura->thirdai[neural_db]) (0.1.0.post0)\n",
      "Requirement already satisfied: langchain in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.0.198)\n",
      "Collecting langchain\n",
      "  Obtaining dependency information for langchain from https://files.pythonhosted.org/packages/c9/b7/f511d1ddfaa1acc04356a7f75ca389bf9e6e5bd19ac368bc786de4063240/langchain-0.0.252-py3-none-any.whl.metadata\n",
      "  Downloading langchain-0.0.252-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (2.0.16)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (3.8.4)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (0.5.8)\n",
      "Collecting langsmith<0.1.0,>=0.0.11 (from langchain)\n",
      "  Obtaining dependency information for langsmith<0.1.0,>=0.0.11 from https://files.pythonhosted.org/packages/bb/63/5016b578465eeee84c630bb38439b1d5c9aca9ccc312843178fdfdc9a5b4/langsmith-0.0.18-py3-none-any.whl.metadata\n",
      "  Downloading langsmith-0.0.18-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (1.24.3)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (1.2.4)\n",
      "Requirement already satisfied: pydantic<2,>=1 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (1.10.9)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<2,>=1->langchain) (4.6.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (2023.5.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
      "Downloading langchain-0.0.252-py3-none-any.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.1/1.4 MB 1.9 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.3/1.4 MB 4.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 0.8/1.4 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.4/1.4 MB 8.1 MB/s eta 0:00:00\n",
      "Downloading langsmith-0.0.18-py3-none-any.whl (31 kB)\n",
      "Installing collected packages: langsmith, langchain\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.0.198\n",
      "    Uninstalling langchain-0.0.198:\n",
      "      Successfully uninstalled langchain-0.0.198\n",
      "Successfully installed langchain-0.0.252 langsmith-0.0.18\n",
      "Requirement already satisfied: openai in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.27.8)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->openai) (0.4.6)\n",
      "Requirement already satisfied: paper-qa in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.5.0)\n",
      "Requirement already satisfied: pypdf in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paper-qa) (3.14.0)\n",
      "Requirement already satisfied: langchain>=0.0.198 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paper-qa) (0.0.252)\n",
      "Requirement already satisfied: openai>=0.27.8 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paper-qa) (0.27.8)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paper-qa) (1.7.4)\n",
      "Requirement already satisfied: PyCryptodome in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paper-qa) (3.18.0)\n",
      "Requirement already satisfied: html2text in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paper-qa) (2020.1.16)\n",
      "Requirement already satisfied: tiktoken>=0.4.0 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from paper-qa) (0.4.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain>=0.0.198->paper-qa) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain>=0.0.198->paper-qa) (2.0.16)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain>=0.0.198->paper-qa) (3.8.4)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain>=0.0.198->paper-qa) (0.5.8)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.11 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain>=0.0.198->paper-qa) (0.0.18)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain>=0.0.198->paper-qa) (2.8.4)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain>=0.0.198->paper-qa) (1.24.3)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain>=0.0.198->paper-qa) (1.2.4)\n",
      "Requirement already satisfied: pydantic<2,>=1 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain>=0.0.198->paper-qa) (1.10.9)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain>=0.0.198->paper-qa) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain>=0.0.198->paper-qa) (8.2.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai>=0.27.8->paper-qa) (4.65.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tiktoken>=0.4.0->paper-qa) (2023.6.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.198->paper-qa) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.198->paper-qa) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.198->paper-qa) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.198->paper-qa) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.198->paper-qa) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.198->paper-qa) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.198->paper-qa) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.198->paper-qa) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.198->paper-qa) (1.5.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.198->paper-qa) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<2,>=1->langchain>=0.0.198->paper-qa) (4.6.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain>=0.0.198->paper-qa) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain>=0.0.198->paper-qa) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain>=0.0.198->paper-qa) (2023.5.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain>=0.0.198->paper-qa) (2.0.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->openai>=0.27.8->paper-qa) (0.4.6)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.198->paper-qa) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\advay\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.198->paper-qa) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install thirdai --upgrade\n",
    "!pip3 install thirdai[neural_db]\n",
    "!pip3 install langchain --upgrade\n",
    "!pip3 install openai --upgrade\n",
    "!pip3 install paper-qa --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thirdai import licensing, neural_db as ndb\n",
    "licensing.deactivate()\n",
    "licensing.activate(\"1FB7DD-CAC3EC-832A67-84208D-C4E39E-V3\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's import the relevant module and define a neural db class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = ndb.NeuralDB(user_id=\"my_user\") # you can use any username, in the future, this username will let you push models to the model hub"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You even load from a base DB from our Bazaar (optional but recommended)\n",
    "\n",
    "We have a model bazaar that provides users with domain specific NeuralDBs that can jumpstart searching on their private documents. The Bazaar has two main types of DBs\n",
    "\n",
    "1. Base DBs: These come with models that have either general QnA capabilities or domain specific capabilities like search on Medical Documents, Financial documents or Contracts. These come with an empty data index into which users can insert their files.\n",
    "\n",
    "2. Pre-Indexed DBs: These are ready-to-search DBs that come with pre-trained models and their corresponding datasets. These are meant to  search through large public datasets like PubMed or Amazon 3MM Products or Stackoverflow issues etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a cache directory\n",
    "import os\n",
    "if not os.path.isdir(\"bazaar_cache\"):\n",
    "    os.mkdir(\"bazaar_cache\")\n",
    "\n",
    "from pathlib import Path\n",
    "from model_bazaar import Bazaar\n",
    "bazaar = Bazaar(cache_dir=Path(\"bazaar_cache\"))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call fetch to refresh list of available DBs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bazaar.fetch() # Optional arg filter=\"model name\" to filter by model name.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the list of all DBs in the Bazaar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Contract Review', 'Finance QnA', 'General QnA']\n"
     ]
    }
   ],
   "source": [
    "print(bazaar.list_model_names())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally load the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 820M/820M [02:05<00:00, 6.51MB/s] \n"
     ]
    }
   ],
   "source": [
    "db = bazaar.get_model(\"General QnA\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert your files\n",
    "\n",
    "Let's insert things into it!\n",
    "\n",
    "Currently, we natively support adding CSV, PDF and DOCX files. We also have a support to automatically scrape and parse URLs. All other file formats have to be converted into CSV files where each row represents a paragraph/text-chunk of the document. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1: CSV files\n",
    "The first example below shows how to insert a CSV file. Please note that a CSV file is required to have a column named \"DOC_ID\" with rows numbered from 0 to n_rows-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "insertable_docs = []\n",
    "csv_files = ['sample_nda.csv']\n",
    "\n",
    "for file in csv_files:\n",
    "    csv_doc = ndb.CSV(\n",
    "        path=file,\n",
    "        id_column=\"DOC_ID\",\n",
    "        strong_columns=[\"passage\"],\n",
    "        weak_columns=[\"para\"],  \n",
    "        reference_columns=[\"passage\"])\n",
    "    #\n",
    "    insertable_docs.append(csv_doc)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2: PDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Advay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "insertable_docs = []\n",
    "pdf_files = ['sample_nda.pdf']\n",
    "\n",
    "for file in pdf_files:\n",
    "    pdf_doc = ndb.PDF(file)\n",
    "    insertable_docs.append(pdf_doc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 3: DOCX files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "insertable_docs = []\n",
    "doc_files = ['sample_nda.docx']\n",
    "\n",
    "for file in doc_files:\n",
    "    doc = ndb.DOCX(file)\n",
    "    insertable_docs.append(doc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 4: Parse from URLs directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_url_data = ndb.parsing_utils.recursive_url_scrape(base_url=\"https://www.thirdai.com/pocketllm/\", max_crawl_depth=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "insertable_docs = []\n",
    "\n",
    "for url, response in valid_url_data:\n",
    "    try:\n",
    "        insertable_docs.append(ndb.URL(url, response))\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert into NeuralDB\n",
    "\n",
    "If you wish to insert without unsupervised training, you can set 'train=False' in the insert() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_ids = db.insert(insertable_docs, train=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above command is intended to be used with a base DB which already has reasonable knowledge of the domain. In general, we always recommend using 'train=True' as shown below.\n",
    "\n",
    "#### Insert and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_ids = db.insert(insertable_docs, train=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you call the insert() method multiple times, the documents will automatically be de-duplicated. If insert=True, then the training will be done multiple times."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search\n",
    "\n",
    "Now let's start searching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In consideration of the business discussions disclosure of Confidential Information and any future business relationship between the parties it is hereby agreed as follows: 1. CONFIDENTIAL INFORMATION. For purposes of this Agreement the term \"Confidential Information\" shall mean any information business plan concept idea know-how process technique program design formula algorithm or work-in-process Request for Proposal (RFP) or Request for Information (RFI) and any responses thereto engineering manufacturing marketing technical financial data or sales information or information regarding suppliers customers employees investors or business operations and other information or materials whether disclosed in written graphic oral or electronic form whether tangible or intangible and in whatever form or medium provided or which is learned or disclosed in the course of discussions studies or other work undertaken between the parties prior to or after the Effective Date.\n",
      "************\n",
      "12. ENTIRE AGREEMENT. This Agreement constitutes the entire agreement with respect to the subject matter hereof and supersedes all prior agreements and understandings between the parties (whether written or oral) relating to the subject matter and may not be amended or modified except in a writing signed by an authorized representative of both parties. The terms of this Agreement relating to the confidentiality and non-use of Confidential Information shall continue after the termination of this Agreement for a period of the longer of (i) five (5) years or (ii) when the Confidential Information no longer qualifies as a trade secret under applicable law.\n",
      "************\n"
     ]
    }
   ],
   "source": [
    "search_results = db.search(\n",
    "    query=\"what is the termination period\",\n",
    "    top_k=2,\n",
    "    on_error=lambda error_msg: print(f\"Error! {error_msg}\"))\n",
    "\n",
    "for result in search_results:\n",
    "    print(result.text)\n",
    "    # print(result.context(radius=1))\n",
    "    # print(result.source)\n",
    "    # print(result.metadata)\n",
    "    print('************')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the search pulled up the right passage that contains the termination period \"(i) five (5) years or (ii) when the confidential information no longer qualifies as a trade secret\" ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidentiality agreement this confidentiality agreement (the “agreement”) is made by and between acme. dba tothemoon inc. with offices at 2025 guadalupe st. suite 260 austin tx 78705 and starwars dba tothemars with offices at the forest moon of endor and entered as of may 3 2023 (“effective date”).\n",
      "************\n",
      "in witness whereof this agreement has been duly executed by the parties hereto as of the latest date set forth below: acme inc. starwars inc. by: by: name: bugs bunny name: luke skywalker title: ceo title: ceo date: may 5 2023 date: may 7 2023\n",
      "************\n"
     ]
    }
   ],
   "source": [
    "search_results = db.search(\n",
    "    query=\"made by and between\",\n",
    "    top_k=2,\n",
    "    on_error=lambda error_msg: print(f\"Error! {error_msg}\"))\n",
    "\n",
    "for result in search_results:\n",
    "    print(result.text)\n",
    "    # print(result.context(radius=1))\n",
    "    # print(result.source)\n",
    "    # print(result.metadata)\n",
    "    print('************')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the search pulled up the right passage again that has \"made by and between\".\n",
    "\n",
    "Now let's ask a tricky question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6. excluded information. the parties agree that confidential information of the other party shall not include any information to the extent that the information: (i) is or at any time becomes a part of the public domain through no act or omission of the receiving party; (ii) is independently discovered or developed by the receiving party without use of the disclosing party’s confidential information; (iii) is rightfully obtained from a third party without any obligation of confidentiality; or (iv) is already known by the receiving party without any obligation of confidentiality prior to obtaining the confidential information from the disclosing party.\n",
      "************\n",
      "2. need to know. the receiving party shall limit its disclosure of the other party’s confidential information to those of its officers and employees and subcontractors (i) to which such disclosure is necessary for purposes of the discussions contemplated by this agreement and (ii) who have agreed in writing to be bound by provisions no less restrictive than those set forth in this agreement.\n",
      "************\n"
     ]
    }
   ],
   "source": [
    "search_results = db.search(\n",
    "    query=\"who are the parties involved?\",\n",
    "    top_k=2,\n",
    "    on_error=lambda error_msg: print(f\"Error! {error_msg}\"))\n",
    "\n",
    "for result in search_results:\n",
    "    print(result.text)\n",
    "    # print(result.context(radius=1))\n",
    "    # print(result.source)\n",
    "    # print(result.metadata)\n",
    "    print('************')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops! looks like when we search for \"parties involved\", we do not get the correct paragraph in the 1st position (we should be expecting the first paragraph as the correct results instead fo the last). \n",
    "\n",
    "No worries, we'll show shot to teach the model to correct it's retrieval.\n",
    "\n",
    "### RLHF\n",
    "\n",
    "Let's go over some of NeuralDB's advanced features. The first one is text-to-text association. This allows you to teach the model that two keywords, phrases, or concepts are related.\n",
    "\n",
    "Based on the above example, let's teach the model that \"parties involved\" and the phrase \"made by between\" are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.associate(source=\"parties involved\", target=\"made by and between\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's search again with the same query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidentiality agreement this confidentiality agreement (the “agreement”) is made by and between acme. dba tothemoon inc. with offices at 2025 guadalupe st. suite 260 austin tx 78705 and starwars dba tothemars with offices at the forest moon of endor and entered as of may 3 2023 (“effective date”).\n",
      "************\n",
      "in witness whereof this agreement has been duly executed by the parties hereto as of the latest date set forth below: acme inc. starwars inc. by: by: name: bugs bunny name: luke skywalker title: ceo title: ceo date: may 5 2023 date: may 7 2023\n",
      "************\n"
     ]
    }
   ],
   "source": [
    "search_results = db.search(\n",
    "    query=\"who are the parties involved?\",\n",
    "    top_k=2,\n",
    ")\n",
    "\n",
    "for result in search_results:\n",
    "    print(result.text)\n",
    "    # print(result.source)\n",
    "    # print(result.metadata)\n",
    "    print('************')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There you go! In just a line, you taught the model to correct itself and retrieve the correct result.\n",
    "\n",
    "Now, let's see the 2nd option which is text-to-result association. Let's say that you know that \"parties involved\" should go the paragraph with DOC_ID=0, you can simply teach the model to associate the query to the corresponding label using the following API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.text_to_result(\"made by and between\",0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to use the above RLHF methods in a batch instead of a single sample, you can simply use the batched versions of the APIs as shown next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.associate_batch([(\"parties involved\",\"made by and between\"),(\"date of signing\",\"duly executed\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.text_to_result_batch([(\"parties involved\",0),(\"date of signing\",16)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Training (Optional)\n",
    "\n",
    "If you have supervised data for a specific CSV file in your list, you can simply train the DB on that file by specifying a source_id = source_ids[*file_number_in_your_list*].\n",
    "\n",
    "Note: The supervised file should have the query_column and id_column that you specify in the following call. The id_column should match the id_column that you specified in the \"Prep CSV Data\" step or default to \"DOC_ID\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_files = ['sample_nda_sup.csv']\n",
    "\n",
    "db.supervised_train([ndb.Sup(path, query_column=\"QUERY\", id_column=\"DOC_ID\", source_id=source_ids[0]) for path in sup_files])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Answers from OpenAI using Langchain\n",
    "\n",
    "In this section, we will show how to use LangChain and query OpenAI's QnA module to generate an answer from the references that you retrieve from the above DB. You'll have to specify your own OpenAI key for this module to work. You can replace this segment with any other generative model of your choice. You can choose to use an source model like MPT or Dolly for answer generation with the same prompt that you use with OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from paperqa.prompts import qa_prompt\n",
    "from paperqa.chains import make_chain\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name='gpt-3.5-turbo', \n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "qa_chain = make_chain(prompt=qa_prompt, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_references(query):\n",
    "    search_results = db.search(query,top_k=3)\n",
    "    references = []\n",
    "    for result in search_results:\n",
    "        references.append(result.text)\n",
    "    return references\n",
    "\n",
    "def get_answer(query, references):\n",
    "    return qa_chain.run(question=query, context='\\n\\n'.join(references[:3]), answer_length=\"abt 50 words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['confidentiality agreement this confidentiality agreement (the “agreement”) is made by and between acme. dba tothemoon inc. with offices at 2025 guadalupe st. suite 260 austin tx 78705 and starwars dba tothemars with offices at the forest moon of endor and entered as of may 3 2023 (“effective date”).', 'in witness whereof this agreement has been duly executed by the parties hereto as of the latest date set forth below: acme inc. starwars inc. by: by: name: bugs bunny name: luke skywalker title: ceo title: ceo date: may 5 2023 date: may 7 2023', 'in consideration of the business discussions disclosure of confidential information and any future business relationship between the parties it is hereby agreed as follows: 1. confidential information. for purposes of this agreement the term “confidential information” shall mean any information business plan concept idea know-how process technique program design formula algorithm or work-in-process request for proposal (rfp) or request for information (rfi) and any responses thereto engineering manufacturing marketing technical financial data or sales information or information regarding suppliers customers employees investors or business operations and other information or materials whether disclosed in written graphic oral or electronic form whether tangible or intangible and in whatever form or medium provided or which is learned or disclosed in the course of discussions studies or other work undertaken between the parties prior to or after the effective date.']\n"
     ]
    }
   ],
   "source": [
    "query = \"what is the effective date of this agreement?\"\n",
    "\n",
    "references = get_references(query)\n",
    "print(references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The effective date of this agreement is May 3, 2023 (Context).\n"
     ]
    }
   ],
   "source": [
    "answer = get_answer(query, references)\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Save\n",
    "As usual, saving and loading the DB are one-liners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save your db\n",
    "db.save(\"sample_nda.db\")\n",
    "\n",
    "# Loading is just like we showed above, with an optional progress handler\n",
    "db.from_checkpoint(\"sample_nda.db\", on_progress=lambda fraction: print(f\"{fraction}% done with loading.\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
